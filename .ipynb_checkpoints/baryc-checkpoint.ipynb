{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72725ba7-909c-48b9-80ee-4070d1df0c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7dadc8b-86a5-4822-9bca-26d2f0b13dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_gaussians(num_gaussians, num_samples, dim=2, mu_range=(-10,10), sigma_range=(1,1)):\n",
    "    gaussians = []\n",
    "    mus = []\n",
    "    sigmas = []\n",
    "    for _ in range(num_gaussians):\n",
    "        mu = torch.FloatTensor(dim).uniform_(mu_range[0], mu_range[1])\n",
    "        mus.append(mu.squeeze())\n",
    "\n",
    "        A = torch.randn(dim, dim)\n",
    "        sigma = torch.mm(A, A.t()) \n",
    "        sigma += torch.eye(dim) * sigma_range[0] \n",
    "        sigmas.append(sigma.squeeze())\n",
    "\n",
    "        dist = torch.distributions.MultivariateNormal(mu, sigma)\n",
    "        samples = dist.sample([num_samples])\n",
    "        gaussians.append(samples.squeeze())\n",
    "\n",
    "    return torch.stack(gaussians), torch.stack(mus), torch.stack(sigmas)\n",
    "\n",
    "def calc_bc_1d(gs):\n",
    "    '''\n",
    "    Calculating the barycenter of empirical 1D Gaussians\n",
    "    \n",
    "    Parameters:\n",
    "    gs: Tensor(num_slices, num_gaussians, num_samples) \n",
    "    \n",
    "    Return:\n",
    "    means, variances of the barycenters, one per slice\n",
    "    '''\n",
    "    mus = torch.mean(gs, axis=-1)\n",
    "    mus = torch.mean(mus,axis=-1)\n",
    "    vs = torch.var(gs, axis=-1)\n",
    "    vs = torch.sqrt(vs)\n",
    "    vs = torch.mean(vs, axis=-1)\n",
    "    vs = torch.pow(vs, 2)\n",
    "    return mus, vs\n",
    "\n",
    "def plot_slices(sample_slices):\n",
    "    num_slices = sample_slices.shape[0]\n",
    "    fig, axs = plt.subplots(num_slices, figsize=(10, 3 * num_slices))\n",
    "\n",
    "    for i in range(num_slices):\n",
    "        for j in range(sample_slices.shape[1]):\n",
    "            if j == sample_slices.shape[1] - 1:\n",
    "                alpha = 1.0 \n",
    "                linewidth = 4.0  \n",
    "            else:\n",
    "                alpha = 0.2\n",
    "                linewidth = 1.0  \n",
    "            sns.kdeplot(sample_slices[i, j, :].detach().cpu().numpy(), ax=axs[i], alpha=alpha, linewidth=linewidth)\n",
    "       \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def generate_and_plot_slices(gs, bc_mu, bc_sigma, num_samples, num_slices, dim, device, seed=69):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    gs = gs.to(device)\n",
    "    bc_mu = bc_mu.to(device)\n",
    "    bc_sigma = bc_sigma.to(device)\n",
    "\n",
    "    dist = torch.distributions.MultivariateNormal(bc_mu, bc_sigma)\n",
    "    bc_samples = dist.sample([num_samples]).unsqueeze(0).to(torch.double)\n",
    "\n",
    "    sample_projs = torch.randn(dim, num_slices, dtype=torch.double).to(device)\n",
    "    sample_slices_gs = torch.matmul(gs.double(), sample_projs)\n",
    "    sample_slices_gs = sample_slices_gs.permute(2,0,1)\n",
    "\n",
    "    sample_slices_bc = torch.matmul(bc_samples, sample_projs)\n",
    "    sample_slices_bc = sample_slices_bc.permute(2,0,1)\n",
    "\n",
    "    sample_slices = torch.cat([sample_slices_gs, sample_slices_bc], dim=1)\n",
    "\n",
    "    plot_slices(sample_slices)\n",
    "    \n",
    "def calc_bc(gs, num_projs=5000, max_iter=50000, lr=5e-3, err_thresh=5e-3, device=device):\n",
    "    d = gs.shape[2]\n",
    "    gs = gs.float().to(device)\n",
    "    \n",
    "    bc_mu = torch.ones(d, device=device, requires_grad=True)\n",
    "    L = torch.tril(torch.randn((d, d), device=device) * 0.5 + torch.eye(d, device=device) * 1e-3, diagonal=0)\n",
    "    L.requires_grad = True\n",
    "    bc_sigma = L @ L.T #covariance matrix, constructed by choleskys LL^T\n",
    "\n",
    "    optimizer = torch.optim.Adam([bc_mu, L], lr=lr)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    losses = []\n",
    "    for i in range(max_iter):\n",
    "        projs = torch.randn(d, num_projs).to(device)\n",
    "        slices = torch.matmul(gs, projs)\n",
    "        slices = slices.permute(2,0,1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        bc_sigma = L @ L.T\n",
    "        bc_mu_projected = projs.T @ bc_mu\n",
    "        bc_sigma_projected = projs.T @ bc_sigma @ projs\n",
    "\n",
    "        variances = torch.diag(bc_sigma_projected)\n",
    "   \n",
    "        mus_1d, vars_1d = calc_bc_1d(slices)   \n",
    "\n",
    "        loss = criterion(mus_1d, bc_mu_projected) + criterion(vars_1d, variances)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if losses[-1] < err_thresh * losses[0]:\n",
    "            print(f\"Converged in {i} iteration(s)\")\n",
    "            break\n",
    "\n",
    "    bc_mu = bc_mu.detach().cpu()\n",
    "    bc_sigma = bc_sigma.detach().cpu()\n",
    "    return bc_mu, bc_sigma, losses\n",
    "\n",
    "def calc_bc_lot(gs, max_iter=1000, err_thresh=8e-7):\n",
    "    gs = gs.cpu().numpy()\n",
    "    d = gs[0].shape[1] \n",
    "    n_samples = len(gs)\n",
    "\n",
    "    mu0 = gs[0].mean(axis=0)\n",
    "    sigma0 = np.cov(gs[0], rowvar=False)\n",
    "\n",
    "    muhats = np.empty((n_samples,) + mu0.shape)\n",
    "    sigmahats = np.empty((n_samples,) + sigma0.shape)\n",
    "    \n",
    "    mu0_prev, sigma0_prev = mu0, sigma0\n",
    "    \n",
    "    delta0 = None\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        for j, sample in enumerate(gs):\n",
    "            mu = sample.mean(axis=0)\n",
    "            sigma = np.cov(sample, rowvar=False)\n",
    "            \n",
    "            sigma0 += np.eye(d) * 1e-6\n",
    "            sigma += np.eye(d) * 1e-6\n",
    "            \n",
    "            A = sqrtm(sigma) @ np.linalg.inv(sqrtm(sigma0))\n",
    "            b = mu - A @ mu0\n",
    "            \n",
    "            muhats[j] = A @ mu0.T + b\n",
    "            sigmahats[j] = A @ sigma0 @ A.T\n",
    "\n",
    "        mu0 = muhats.mean(axis=0)\n",
    "        sigma0 = sigmahats.mean(axis=0)\n",
    "\n",
    "        delta_mu = np.linalg.norm(mu0 - mu0_prev)\n",
    "        delta_sigma = np.linalg.norm(sigma0 - sigma0_prev)\n",
    "        \n",
    "        if delta0 is None:\n",
    "            delta0 = max(delta_mu, delta_sigma)\n",
    "        delta_rel =  max(delta_mu, delta_sigma) / delta0\n",
    "\n",
    "        if delta_rel < err_thresh:\n",
    "            print(f\"Converged in {i} iteration(s)\")\n",
    "            break\n",
    "        \n",
    "        mu0_prev, sigma0_prev = mu0, sigma0\n",
    "\n",
    "    return torch.tensor(mu0), torch.tensor(sigma0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687a2efd-e877-4003-ae82-919a216394d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_Gaussians = 100\n",
    "num_samples = 500\n",
    "dim = 10\n",
    "mu_range = (-100,100)\n",
    "sigma_range = (0.5,40)\n",
    "\n",
    "gs, mus, sigmas = make_gaussians(num_Gaussians, num_samples, dim=dim, mu_range=mu_range,sigma_range=sigma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c39c0-eb78-4600-b6d5-a36f88be84ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tik = time.time()\n",
    "bc_mu, bc_sigma,losses = calc_bc(gs)\n",
    "tok = time.time()\n",
    "\n",
    "print(\"wall clock: \", tok-tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252ec5e-abc3-464f-8074-1120f79f67ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_and_plot_slices(gs, bc_mu, bc_sigma, num_samples=num_samples, num_slices=3, dim=dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66599766-a384-4203-b642-df905267a01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tik = time.time()\n",
    "bc_mu_lot, bc_sigma_lot = calc_bc_lot(gs, err_thresh=5e-3)\n",
    "tok = time.time()\n",
    "\n",
    "print(\"wall clock: \", tok-tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dcea2e-b38d-4181-bb62-a71467d29785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_and_plot_slices(gs, bc_mu_lot, bc_sigma_lot, num_samples=num_samples, num_slices=3, dim=dim, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
